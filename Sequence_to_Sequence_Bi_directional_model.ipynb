{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence to Sequence Bi-directional model",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG2gJWdgKnn0"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import string\r\n",
        "from string import digits\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\r\n",
        "from keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed, Flatten, Dropout, Bidirectional\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.models import Model, Sequential, load_model\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from numpy import array, argmax\r\n",
        "from numpy.random import rand, shuffle\r\n",
        "from nltk.translate.bleu_score import corpus_bleu\r\n",
        "from nltk.translate.bleu_score import sentence_bleu\r\n",
        "import scipy\r\n",
        "import statsmodels\r\n",
        "import sklearn\r\n",
        "import tensorflow\r\n",
        "import keras\r\n",
        "from io import open\r\n",
        "import unicodedata\r\n",
        "import random\r\n",
        "import math\r\n",
        "import os\r\n",
        "import time\r\n",
        "import re\r\n",
        "import sys\r\n",
        "from unicodedata import normalize\r\n",
        "from numpy import array\r\n",
        "from pickle import dump, load\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.utils.vis_utils import plot_model\r\n",
        "from keras.layers import RepeatVector, TimeDistributed\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "\r\n",
        "INDIC_NLP_LIB_HOME=r\"/content/drive/MyDrive/anoopkunchukuttan-indic_nlp_library-eccde81/src\"\r\n",
        "INDIC_NLP_RESOURCES=r\"/content/drive/MyDrive/indic_nlp_resources-master\"\r\n",
        "sys.path.append(r'{}'.format(INDIC_NLP_LIB_HOME))\r\n",
        "from indicnlp import common\r\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\r\n",
        "from indicnlp import loader\r\n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\r\n",
        "from indicnlp.tokenize import indic_tokenize"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7c37-SAOycI"
      },
      "source": [
        "def load_doc(filename):\r\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\r\n",
        "    text = file.read()\r\n",
        "    file.close()\r\n",
        "    return text\r\n",
        "\r\n",
        "def to_pairs(hindi_text, telugu_text):\r\n",
        "    hindi_lines = hindi_text.strip().split('\\n')\r\n",
        "    telugu_lines = telugu_text.strip().split('\\n')\r\n",
        "    pairs = []\r\n",
        "    for i in range(len(telugu_lines)):\r\n",
        "        pairs.append([])\r\n",
        "        pairs[i].append(pre_process_hindi_sentence(hindi_lines[i]))\r\n",
        "        pairs[i].append(pre_process_telugu_sentence(telugu_lines[i]))\r\n",
        "    return pairs\r\n",
        "\r\n",
        "def clean_text(text):\r\n",
        "    text = text.replace(u',','')\r\n",
        "    text = text.replace(u'\"','')\r\n",
        "    text = text.replace(u'\"','')\r\n",
        "    text = text.replace(u\"‘‘\",'')\r\n",
        "    text = text.replace(u\"’’\",'')\r\n",
        "    text = text.replace(u\"''\",'')\r\n",
        "    text = text.replace(u\"।\",'')\r\n",
        "    text=text.replace(u',','')\r\n",
        "    text=text.replace(u'\"','')\r\n",
        "    text=text.replace(u'(','')\r\n",
        "    text=text.replace(u')','')\r\n",
        "    text=text.replace(u'\"','')\r\n",
        "    text=text.replace(u':','')\r\n",
        "    text=text.replace(u\"'\",'')\r\n",
        "    text=text.replace(u\"‘‘\",'')\r\n",
        "    text=text.replace(u\"’’\",'')\r\n",
        "    text=text.replace(u\"''\",'')\r\n",
        "    text=text.replace(u\".\",'')\r\n",
        "    text=text.replace(u\"-\",'')\r\n",
        "    text=text.replace(u\"।\",'')\r\n",
        "    text=text.replace(u\"?\",'')\r\n",
        "    text=text.replace(u\"\\\\\",'')\r\n",
        "    text=text.replace(u\"_\",'')\r\n",
        "    text= re.sub(\"'\", '', text)\r\n",
        "    text=re.sub('[0-9+\\-*/.%]', '', text)\r\n",
        "    text=text.strip()\r\n",
        "    text=re.sub(' +', ' ',text)\r\n",
        "    exclude = set(string.punctuation)\r\n",
        "    text= ''.join(ch for ch in text if ch not in exclude)\r\n",
        "    return text\r\n",
        "\r\n",
        "def pre_process_hindi_sentence(line):\r\n",
        "    line=re.sub('[a-zA-Z]', '', line)\r\n",
        "    line = clean_text(line)\r\n",
        "    remove_nuktas = False\r\n",
        "    factory = IndicNormalizerFactory()\r\n",
        "    normalizer = factory.get_normalizer(\"hi\",remove_nuktas)\r\n",
        "    line = normalizer.normalize(line)\r\n",
        "    tokens = list()\r\n",
        "    for t in indic_tokenize.trivial_tokenize(line):\r\n",
        "        tokens.append(t)\r\n",
        "    line = tokens\r\n",
        "    line = [word for word in line if not re.search(r'\\d', word)]\r\n",
        "    line = ' '.join(line)\r\n",
        "    line = 'START_ '+ line + ' _END'\r\n",
        "    return (line)\r\n",
        "\r\n",
        "def pre_process_telugu_sentence(line):\r\n",
        "    line=re.sub('[a-zA-Z]', '', line)\r\n",
        "    line = clean_text(line)\r\n",
        "    remove_nuktas = False\r\n",
        "    factory = IndicNormalizerFactory()\r\n",
        "    normalizer = factory.get_normalizer(\"hi\",remove_nuktas)\r\n",
        "    line = normalizer.normalize(line)\r\n",
        "    tokens = list()\r\n",
        "    for t in indic_tokenize.trivial_tokenize(line):\r\n",
        "        tokens.append(t)\r\n",
        "    line = tokens\r\n",
        "    line = [word for word in line if not re.search(r'\\d', word)]\r\n",
        "    line = ' '.join(line)\r\n",
        "    line = 'START_ '+ line + ' _END'\r\n",
        "    return (line)\r\n",
        "\r\n",
        "hindi_text = load_doc('/content/drive/MyDrive/surya_hindi_telugu/HIN.txt')\r\n",
        "telugu_text = load_doc('/content/drive/MyDrive/surya_hindi_telugu/TEL.txt')\r\n",
        "pairs = to_pairs(hindi_text, telugu_text)\r\n",
        "df = pd.DataFrame(pairs)\r\n",
        "df.columns = [\"hin\", \"tel\"]\r\n",
        "#df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZFyevQqOyik"
      },
      "source": [
        "lines = df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FnkmhKoOym-",
        "outputId": "eeff4a62-ea74-42c0-bd77-1871704e4c21"
      },
      "source": [
        "all_hin_words=set()\r\n",
        "for hin in lines.hin:\r\n",
        "    for word in hin.split():\r\n",
        "        if word not in all_hin_words:\r\n",
        "            all_hin_words.add(word)\r\n",
        "\r\n",
        "\r\n",
        "all_telugu_words=set()\r\n",
        "for tel in lines.tel:\r\n",
        "    for word in tel.split():\r\n",
        "        if word not in all_telugu_words:\r\n",
        "            all_telugu_words.add(word)\r\n",
        "\r\n",
        "#print (all_hin_words)\r\n",
        "print (len(all_hin_words))\r\n",
        "print (len(all_telugu_words))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12560\n",
            "16242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eAbfPrOOy_a",
        "outputId": "7eee1439-9daa-4e3b-a4a2-9ab51fe314fb"
      },
      "source": [
        "# Max Length of source sequence\r\n",
        "lenght_list=[]\r\n",
        "for l in lines.hin:\r\n",
        "    lenght_list.append(len(l.split(' ')))\r\n",
        "max_length_src = np.max(lenght_list)\r\n",
        "print (max_length_src)\r\n",
        "\r\n",
        "# Max Length of target sequence\r\n",
        "lenght_list=[]\r\n",
        "for l in lines.tel:\r\n",
        "    lenght_list.append(len(l.split(' ')))\r\n",
        "max_length_tar = np.max(lenght_list)\r\n",
        "print (max_length_tar)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "85\n",
            "59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qKm9n7yOzB-",
        "outputId": "54a8a63d-8cdc-40a1-afa6-a9cba0536148"
      },
      "source": [
        "input_words = sorted(list(all_hin_words))\r\n",
        "target_words = sorted(list(all_telugu_words))\r\n",
        "num_encoder_tokens = len(all_hin_words)\r\n",
        "num_decoder_tokens = len(all_telugu_words)\r\n",
        "num_encoder_tokens, num_decoder_tokens\r\n",
        "num_encoder_tokens += 1\r\n",
        "num_decoder_tokens += 1 # For zero padding\r\n",
        "num_decoder_tokens"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJDE99HYOzGf"
      },
      "source": [
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\r\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\r\n",
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\r\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ordAXQV_OzIi",
        "outputId": "fccb1888-ab60-4b1c-b9e0-dae9284aea37"
      },
      "source": [
        "# Train - Test Split\r\n",
        "X, y = lines.hin, lines.tel\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\r\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9899,), (1100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C41giN_oOzNA"
      },
      "source": [
        "X_train.to_pickle('X_train.pkl')\r\n",
        "X_test.to_pickle('X_test.pkl')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iboLSsrOzPD"
      },
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\r\n",
        "    while True:\r\n",
        "        # range(start, stop, step)\r\n",
        "        for j in range(0, len(X), batch_size):\r\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\r\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\r\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\r\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\r\n",
        "                for t, word in enumerate(input_text.split()):\r\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\r\n",
        "                for t, word in enumerate(target_text.split()):\r\n",
        "                    if t<len(target_text.split())-1:\r\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\r\n",
        "                    if t>0:\r\n",
        "                        # decoder target sequence (one hot encoded)\r\n",
        "                        # does not include the START_ token\r\n",
        "                        # Offset by one timestep\r\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\r\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fPZk6oBOzTt"
      },
      "source": [
        "latent_dim = 500\r\n",
        "vec_len = 300 # Length of the vector that we willl get from the embedding layer\r\n",
        "dropout_rate = 0.2 # Rate of the dropout layers\r\n",
        "encoder_inputs = Input(shape=(None,))\r\n",
        "\r\n",
        "#enc_emb =  Embedding(num_encoder_tokens, vec_len, mask_zero = True)(encoder_inputs)\r\n",
        "#enc_emb =  Embedding(num_encoder_tokens, vec_len)(encoder_inputs)\r\n",
        "enc_emb = Embedding(input_dim = num_encoder_tokens, output_dim = vec_len, mask_zero = True)(encoder_inputs)\r\n",
        "\r\n",
        "encoder_dropout = (TimeDistributed(Dropout(rate = dropout_rate)))(enc_emb)\r\n",
        "encoder_lstm1 = Bidirectional(LSTM(latent_dim, return_sequences=True), merge_mode='sum')(encoder_dropout)\r\n",
        "encoder_lstm2 = Bidirectional(LSTM(latent_dim, return_sequences=True), merge_mode='sum')(encoder_lstm1)\r\n",
        "encoder_lstm3 = Bidirectional(LSTM(latent_dim, return_sequences=True), merge_mode='sum')(encoder_lstm2)\r\n",
        "encoder_LSTM4_layer = LSTM(latent_dim, return_state=True)\r\n",
        "encoder_outputs, state_h, state_c = encoder_LSTM4_layer(encoder_lstm3)\r\n",
        "# We discard `encoder_outputs` and only keep the states.\r\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msbk6iVcOzVm"
      },
      "source": [
        "decoder_inputs = Input(shape=(None,))\r\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, vec_len, mask_zero = True)\r\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\r\n",
        "decoder_dropout = (TimeDistributed(Dropout(rate = dropout_rate)))(dec_emb)\r\n",
        "# We set up our decoder to return full output sequences,\r\n",
        "# and to return internal states as well. We don't use the\r\n",
        "# return states in the training model, but we will use them in inference.\r\n",
        "\r\n",
        "\r\n",
        "decoder_LSTM_layer = LSTM(latent_dim, return_sequences=True)\r\n",
        "decoder_LSTM = decoder_LSTM_layer(decoder_dropout, initial_state = encoder_states)\r\n",
        "\r\n",
        "decoder_LSTM_2_layer = LSTM(latent_dim, return_sequences=True, return_state=True)\r\n",
        "decoder_outputs,_,_ = decoder_LSTM_2_layer(decoder_LSTM)\r\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\r\n",
        "\r\n",
        "# Define the model that will turn\r\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\r\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtoGsrxlOzZ9",
        "outputId": "dc68e8b3-aa7e-43f1-d903-8f8e3e61246d"
      },
      "source": [
        "model.summary()\r\n",
        "\r\n",
        "# Define a checkpoint callback :\r\n",
        "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \r\n",
        "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\r\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 300)    3768300     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 300)    0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, None, 500)    3204000     time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, None, 500)    4004000     bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    4872900     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, None, 500)    4004000     bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, None, 300)    0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, 500), (None, 2002000     bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, None, 500)    1602000     time_distributed_1[0][0]         \n",
            "                                                                 lstm_3[0][1]                     \n",
            "                                                                 lstm_3[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, None, 500),  2002000     lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 16243)  8137743     lstm_5[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 33,596,943\n",
            "Trainable params: 33,596,943\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsaOwEcSOzb_",
        "outputId": "617e7660-82f3-4708-d104-60402c093920"
      },
      "source": [
        "train_samples = len(X_train)\r\n",
        "val_samples = len(X_test)\r\n",
        "batch_size = 80\r\n",
        "epochs = 10\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "\r\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\r\n",
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\r\n",
        "                    steps_per_epoch = train_samples//batch_size,\r\n",
        "                    epochs=epochs,\r\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\r\n",
        "                    validation_steps = val_samples//batch_size)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "123/123 [==============================] - 2949s 24s/step - loss: 1.6337 - acc: 0.0827 - val_loss: 1.5019 - val_acc: 0.1083\n",
            "Epoch 2/10\n",
            "123/123 [==============================] - 2911s 24s/step - loss: 1.4556 - acc: 0.1059 - val_loss: 1.4934 - val_acc: 0.1099\n",
            "Epoch 3/10\n",
            "123/123 [==============================] - 2915s 24s/step - loss: 1.4294 - acc: 0.1035 - val_loss: 1.4734 - val_acc: 0.1127\n",
            "Epoch 4/10\n",
            "123/123 [==============================] - 2916s 24s/step - loss: 1.3739 - acc: 0.1120 - val_loss: 1.4643 - val_acc: 0.1173\n",
            "Epoch 5/10\n",
            "123/123 [==============================] - 2931s 24s/step - loss: 1.3299 - acc: 0.1172 - val_loss: 1.4757 - val_acc: 0.1188\n",
            "Epoch 6/10\n",
            "123/123 [==============================] - 2917s 24s/step - loss: 1.2894 - acc: 0.1213 - val_loss: 1.4725 - val_acc: 0.1201\n",
            "Epoch 7/10\n",
            "123/123 [==============================] - 2928s 24s/step - loss: 1.2588 - acc: 0.1268 - val_loss: 1.4645 - val_acc: 0.1218\n",
            "Epoch 8/10\n",
            "123/123 [==============================] - 2923s 24s/step - loss: 1.2200 - acc: 0.1322 - val_loss: 1.4612 - val_acc: 0.1266\n",
            "Epoch 9/10\n",
            "123/123 [==============================] - 2911s 24s/step - loss: 1.1870 - acc: 0.1375 - val_loss: 1.4541 - val_acc: 0.1215\n",
            "Epoch 10/10\n",
            "123/123 [==============================] - 2860s 23s/step - loss: 1.1595 - acc: 0.1434 - val_loss: 1.4597 - val_acc: 0.1306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f45aabe7198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU28W8WvOzgO"
      },
      "source": [
        "#save the model\r\n",
        "model.save_weights('nmt_weights.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pbzbn-vOziH"
      },
      "source": [
        "#load the model\r\n",
        "model.load_weights('nmt_weights.h5')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lH1XJFyOzly"
      },
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\r\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\r\n",
        "\r\n",
        "# Decoder setup\r\n",
        "# Below tensors will hold the states of the previous time step\r\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\r\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\r\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\r\n",
        "\r\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\r\n",
        "decoder_dropout2 = (TimeDistributed(Dropout(rate = dropout_rate)))(dec_emb2)\r\n",
        "decoder_LSTM2 = decoder_LSTM_layer(decoder_dropout2, initial_state = decoder_states_inputs)\r\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_LSTM_2_layer(decoder_LSTM2)\r\n",
        "decoder_states2 = [state_h2, state_c2]\r\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) #A dense softmax layer to generate prob dist. over the target vocabulary\r\n",
        "\r\n",
        "\r\n",
        "# Final decoder model\r\n",
        "decoder_model = Model(\r\n",
        "    [decoder_inputs] + decoder_states_inputs,\r\n",
        "    [decoder_outputs2] + decoder_states2)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfIlKLJ6CxVQ"
      },
      "source": [
        "def decode_sequence(input_seq):\r\n",
        "    # Encode the input as state vectors.\r\n",
        "    states_value = encoder_model.predict(input_seq)\r\n",
        "    # Generate empty target sequence of length 1.\r\n",
        "    target_seq = np.zeros((1,1))\r\n",
        "    # Populate the first character of target sequence with the start character.\r\n",
        "    target_seq[0, 0] = target_token_index['START_']\r\n",
        "\r\n",
        "    # Sampling loop for a batch of sequences\r\n",
        "    # (to simplify, here we assume a batch of size 1).\r\n",
        "    stop_condition = False\r\n",
        "    decoded_sentence = ''\r\n",
        "    while not stop_condition:\r\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\r\n",
        "\r\n",
        "        # Sample a token\r\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\r\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\r\n",
        "        decoded_sentence += ' '+sampled_char\r\n",
        "\r\n",
        "        # Exit condition: either hit max length\r\n",
        "        # or find stop character.\r\n",
        "        if (sampled_char == '_END' or\r\n",
        "           len(decoded_sentence) > 98):\r\n",
        "            stop_condition = True\r\n",
        "\r\n",
        "        # Update the target sequence (of length 1).\r\n",
        "        target_seq = np.zeros((1,1))\r\n",
        "        target_seq[0, 0] = sampled_token_index\r\n",
        "\r\n",
        "        # Update states\r\n",
        "        states_value = [h, c]\r\n",
        "\r\n",
        "    return decoded_sentence"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDwV5OIrCxh_"
      },
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\r\n",
        "k=-1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB5lkbs-Cxu1",
        "outputId": "a5ce59bb-de6e-438d-b1c6-0e730295bda6"
      },
      "source": [
        "k+=1\r\n",
        "(input_seq, actual_output), _ = next(train_gen)\r\n",
        "decoded_sentence = decode_sequence(input_seq)\r\n",
        "print('Input hindi sentence:', X_train[k:k+1].values[0])\r\n",
        "print('Actual telugu Translation:', y_train[k:k+1].values[0][6:-4])\r\n",
        "print('Predicted telugu Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input hindi sentence: START_ चीनी का पाचन होते समय उत्पन्न होने वाले एसिड के कारण ऐसा होता है _END\n",
            "Actual telugu Translation:  చక్కెర జీర్ణక్రియ సమయంలో ఉత్పత్తి అయ్యే ఆమ్లం వల్ల ఇది జరుగుతుంది \n",
            "Predicted telugu Translation:  ఈ వ్యాధి ఎ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JbesUsIDVzi",
        "outputId": "0c2f57b9-d114-4df2-e500-e987e5f79aba"
      },
      "source": [
        "k+=1\r\n",
        "(input_seq, actual_output), _ = next(train_gen)\r\n",
        "decoded_sentence = decode_sequence(input_seq)\r\n",
        "print('Input hindi sentence:', X_train[k:k+1].values[0])\r\n",
        "print('Actual telugu Translation:', y_train[k:k+1].values[0][6:-4])\r\n",
        "print('Predicted telugu Translation:', decoded_sentence[:-4])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input hindi sentence: START_ वर्ष के बच्चे आईयू विटामिन ए की एक खुराक हर महीने पर देना _END\n",
            "Actual telugu Translation:  సంవత్సరాల పిల్లలు ప్రతి నెలలకు మోతాదు \n",
            "Predicted telugu Translation:  ఈ వ్యాధి ఎ \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}